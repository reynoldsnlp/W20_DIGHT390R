# NLP with PyTorch, ch 6, Sequence Modeling for Natural Language Processing

1. There are several different levels at which language can be considered
   *sequential* data. What are some examples?

1. What is a *hidden state* (or *hidden representation*)? How is it used in
   sequence modeling?

1. Explain Figures 6-1 and 6-2. In this graph, what is being learned?

1. What is the broad difference in the purposes of RNNs and CNNs?

1. What is masking?

1. In a classification task, which is most useful, intermediate hidden states
   or the final hidden state?
